									推荐算法
一、推荐系统的思想
	知你所想，精准推荐
		- 利用用户和物品的特征信息，给用户推荐那些具有用户喜欢的特征的物品。
	物以类聚
		- 利用用户喜欢过的物品，给用户推荐与他喜欢的物品相似的物品。
	人以群分
		- 利用和用户相似的其他用户，给用户推荐那些跟他们兴趣爱好想死你的其他用户喜欢的物品。
二、推荐系统的分类
	根据实时性分类：							根据推荐是否个性化分类：
		- 离线推荐									- 基于统计的推荐
		- 实时推荐									- 个性化推荐
	根据推荐原则分类：							根据数据源分类：
		- 基于相似度推荐							- 基于人口统计学的推荐
		- 基于知识推荐								- 基于内容的推荐
		- 基于模型推荐								- 基于协同过滤的推荐（基于近邻、基于模型）
三、基于人口统计学推荐算法
	数据源是User信息，包括User的标签信息等，通过标签可以发现User之间的相似性，然后推荐与用户兴趣爱好相似用户喜欢的物品。
四、基于内容的推荐算法（Content Base）
	数据源是Item信息，包括Item的标签信息等，通过标签可以发现Item之间的相似性，然后推荐与用户喜欢的物品相似的物品。
五、协同过滤算法之最近邻算法
	数据来源是用户的行为。
	基于内容（Content Base）主要利用的是用户评价过的物品的内容特征，而CF方法还可以利用其它用户评分过的物品内容。
	基于假设：“跟你喜好相似的人喜欢的物品你有可能喜欢” 或者 “跟你喜欢的物品相似的物品你可能喜欢”	
	分类：
	User-based:
		基于User的协同过滤，通过不同用户对Item的评分，评测User之间的相似性，然后基于用户之间的相似性作出推荐。
	Item-based:
		基于Item的协同过滤，通过用户对不同Item的评分，评测Item之间的相似性，然后基于物品之间的相似性作出推荐。
六、机器学习
	无监督学习（Unsupervised Learning）
		聚类
			- k均值（k-means）
				> 核心思想： 由用户指定K个初始质心（initial centroids）, 以作为聚类的类别（cluster), 重复迭代
					直至算法收敛。
				> 基本算法流程：
					- 选取k个初始质心
					- repeat
						对每个样本点，计算得到距离最近的质心，将其类别标记为其质心所在的类别
						重新计算k个cluster对应的质心
					- until质心不在发生变化，或者迭代达到上限
			- 基于密度的聚类
			- 最大期望聚类
		降维
			- 潜语义分析（LSA）
			- 主成分分析（PCA）
			- 奇异值分解（SVD）
	监督学习（Supervised Learning）
		- Classification(分类)：分类问题预测数据属于哪一类别。--离散
			分类算法：
				- K-NN 最近邻（k-nearest-neighbour）
					通过测量不同特征之间的距离进行分类，它的思路是：如果一个样本在特征空间中的k个最相似（即特征空间
					中最邻近）的样本中的大多数属于某一个类别，则该样本也属于这个类别，其中k通常是不大于20的整数。
					KNN算法中，所选的邻居都是已经正确分类的对象
					算法步骤：
						> 计算测试数据与训练数据之间的距离
						> 按照距离的递增关系进行排序
						> 选取距离最小的k个点
						> 确定前k个点所在的类别出现的频率
						> 返回前k个点中出现频率最高的类别作为测试数据的预测分类
				
				- 决策树
					决策树是一系列规则的列表，根据特征分类
					决策树的本质，是从训练数据集中归纳出一组if-then规则 
				- Logistic Regression 逻辑斯谛回归
					使用Sigmoid压缩函数 g(z) = 1 / (1 + e **-z)进行分类，当z > 0时， g(z) > 0.5, 当z < 0时， g(z) < 0.5
					当z对应的表达式为分类边界时，恰好有分类边界两侧对应的z正负不同，也就使得分类边界两边g(z) > 0.5, g(x) < 0.5
					即g(z) > 0.5分成一类，g(z) < 0.5分成一类
			分类算法评测：
				- 精确率：所有预测为正类的数据中，预测正确的比例。 P = TP/(TP + FP)
				- 召回率：所有实际为正类的数据中，被正确预测找出的比例。 R = TP/(TP + FN)
		- Regression(回归)：回归问题根据数据预测一个数值。 --连续
			回归算法：
				- 线性回归（linear regression）
					求线性回归常用的算法：
					- 最小二乘法，可以求出平方损失函数的最小值
						> 视图找到一条直线，使所有样本到直线上的欧式距离之和最小
					- 梯度下降法，可以求任意损失函数的最小值
				- 非线性回归
	监督学习三要素：
		- 模型(model): 总结数据的内在规律，用数学函数描述的系统
		- 策略(strategy)：选取最优模型的评价标准
		- 算法(algorithm)：选取最优模型的具体方法

七、推荐系统
	基于人口统计学的推荐：用户画像（user profiling)
	基于内容的推荐：余弦相似度
		对于物品的特征提取 --打标签
		对于文本信息的特征提取--关键字
	特征工程：
		数值型特征处理：归一化（feature_new = feature_old/(feature_max - feature_min)）， 离散化
		类别性特征处理
		时间型特征处理
	基于协同过滤的推荐（CF）
		- 基于近邻的协同过滤
			> 基于用户的协同过滤（User-CF）:在一般的应用中采用的是K-NN算法
			User-CF和基于人口统计学的推荐机制比较：
				- 两者都是计算用的相似度，并基于相似的的邻居用户群计算推荐
				- 不同的是如何计算用户的相似度：人口统计学的特征是只考虑用户本身的特征，而User-CF是在用户
				  历史偏好的数据上计算相似性，他的基本假设是‘喜欢类似物品的用户具有相同或者相似的口味’
			> 基于物品的协同过滤（Item-CF）
			Item-CF和基于内容的推荐（CB）比较：
				- 两者都是基于物品相似度进行推荐，只是相似度计算方法不同，Item-CF从用户的历史行为数据推断物品
				  之间的相似性，CB是基于物品本身的属性特征信息进行推荐
		User-CF和Item-CF的使用场景：
			Item-CF：电商，电影，音乐网站，物品数量比较固定，用户数量远大于物品数量，不易计算用户相似性，使用Item-CF更加稳定
			User-CF：新闻网站，物品（新闻文本，更新非常快）数量可能远大于用户数量，不易计算物品相似性，相似性也
			不稳定，使用User-CF更加稳定
		存在问题：
			- 方法的核心是基于历史行为数据，所以对新物品和新用户存在‘冷启动’问题
			- 推荐的效果依赖于用户历史行为数据的多少和准确性
			- 在大部分的实现中，用户历史偏好使用稀疏矩阵存储的，而稀疏矩阵上面的计算有些明显的问题，包括可能少部分
			  人的错误偏好对推荐的准确度有很大的影响
			- 对一些特殊品味的用户，不能给予很好的推荐
		- 基于模型的协同过滤:
			基本思想：
				- 用户具有一定的特征，决定他的偏好选择
				- 物品具有一定的特征，影响用户是否选择他
				- 用户之所以选择一个商品，是因为物品特征和用户特征相匹配
			模型的建立相当于从历史行为数据中提取特征，给用户和物品打上标签。
			> 隐语义模型（LFM）：
				训练模型时，可以基于标签内容来提取物品特征，也可以让模型去发掘物品的潜在特征，这样的模型被
			称为隐语义模型（Latent Factor Model, LFM)
			> 奇异值分解（SVD）
			> 潜在语义分析（LSA）
			> 支撑向量机（SVM）
		基于近邻和基于模型推荐对比：
			- 基于近邻的推荐是在预测时，只用使用已有的用户偏好数据，通过近邻数据来预测用户对新物品的偏好，类似分类
			- 基于模型的推荐是使用用户行为数据来训练模型，找到内在规律，通过模型来预测，类似于回归
	
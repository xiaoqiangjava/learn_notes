						Zookeeper学习
1. Zookeeper是一个分布式的, 开放源代码的分布式应用程序协调服务, 他是集群的管理者, 监视着集群中各个
	节点的状态, Zookeeper提供了文件系统和通知机制. 从设计模式的角度来说，Zookeeper是一个观察者模式。

2. 文件系统--每个子目录都被称作znode, 和文件系统一样我们可以自由的增加或者删除znode, 唯一的不同是
	znode是可以存储数据的, 而文件系统中的目录是不能存储数据的.
	> 1. Persistent Nodes 永久节点，默认创建的就是持久节点
		永久有效的节点, 除非client显示的删除, 否则一直存在, 即client跟Zookeeper断开连接后该节点依旧存在.
	> 2. Ephemeral Nodes 临时节点		
		临时节点, 仅在创建该节点client保持连接期间有效, 一旦连接丢失, Zookeeper会自动删除该节点,
		即客户端与Zookeeper断开连接后该节点会被删除.
	> 3. Sequence Nodes 顺序节点
		顺序节点, client申请创建该节点时, zookeeper会自动在节点路径末尾添加递增序号, 这种类型的节点是
		实现分布式锁, 分布式queue等特殊功能的关键.
		顺序节点不能单独存在, 只能跟Persistent Nodes或者Ephemeral Nodes一起使用
	> 4. Persistent_Sequential 持久化顺序编号目录节点
		客户端与Zookeeper断开连接后该节点依旧存在, 只是Zookeeper对该节点名称进行顺序编号
	> 5. Ephemeral_Sequential 临时顺序编号目录节点
		客户端与Zookeeper断开连接后该节点会被删除, 只是Zookeeper对该节点名称进行顺序编号

3. 通知机制
	客户端注册监听它关心的目录节点, 当目录节点发生变化时(数据改变, 被删除, 子目录节点增加删除)时,
	Zookeeper会通知客户端. 

4. Zookeeper的使用场景
	> 1. 命名服务
		在Zookeeper的文件系统里面创建一个目录, 即有唯一的path. 在我们使用tborg无法确定上游程序的部署机器
		时, 即可与下游程序约定好path, 通过path即能互相探索发现.
	> 2. 配置管理
		程序总是需要配置的, 如果程序分散部署在多台机器上面, 要逐个改变配置就显得困难. 现在把这些配置全部
		放到Zookeeper上面去, 保存在Zookeeper的某一个目录节点上面, 然后所有相关应用程序对这个目录节点进行
		监听, 一旦配置信息发生变化, 每个应用程序就会收到Zookeeper的通知, 然后从Zookeeper中获取新的配置.
	> 3. 集群管理
		所谓集群管理无外乎两点: 是否有机器加入或者退出, 选举master
		> 是否有机器加入或者退出:
			所有机器约定在父目录GroupMembers下面创建临时节点, 然后监听父目录节点的子节点变化信息. 一旦有
			机器挂掉, 该机器与Zookeeper的连接断开, 该机器创建的临时目录节点被删除, 所有其他机器都收到通知.
		> 选举master
			所有的机器创建临时顺序编号目录节点, 每次选取编号顺序最小的机器作为master就好.
	> 4. 分布式锁
		锁服务可以分为两类: 保持独占, 控制时序
		> 保持独占:
			我们将Zookeeper上的一个znode看做是一把锁, 通过createznode的方式来实现, 所有的客户端都去创建
			/distribute_lock节点, 最终创建成功的那个客户端即拥有了锁, 用完之后删除掉自己创建的/distribute_lock 
			节点就释放了锁.
		> 控制时序:
			/distribute_lock节点已经存在, 所有的客户端在改节点下面创建临时顺序编号目录节点, 和选举master
			一样, 编号最小的获得锁, 用完之后删除释放锁.
			如果自己创建的节点不是最小的, 只需要监控比自己节点小的那个节点是否存在, 如果不存在则获得锁.
			如果存在, 则等待Watch通知.
	> 5. 队列管理
		队列可以分为: 同步队列(当一个队列的成员都聚齐是这个队列才可用), FIFO队列
		> 同步队列:
			在约定目录下面创建临时目录节点, 临时节点数目是否是我们要求的数目
		> FIFO队列
			创建临时顺序编号目录, 入列有编号, 出列按编号
			
5. Zookeeper分布式集群搭建
	> 1. 在conf/zoo.cfg配置文件中配置集群信息：
		server.1=hadoop100:2888:3888		# 其中1是每个服务节点的唯一表示，指Zookeeper的data配置目录中新建文件myid中的值
		server.2=hadoop101:2888:3888		# 2888是服务器与集群中的Leader服务器交换信息的端口
		server.3=hadoop102:2888:3888		# 3888是万一集群中的Leader服务器挂了，需要一个端口来重新进行选举，
											# 选出一个新的Leader，而这个端口就是用来执行选举时服务器相互通信的端口
	> 2. 将配置文件分发到其他的机器上面，Zookeeper不需要指定master，master是集群启动的时候通过选举机制选举出来的。
	
6. Zookeeper的选举机制
	每次投票都会把票数投个myid比自己大的服务器，当得到的票数达到配置文件中配置的服务器数量一般以上时，leader产生.当leader
	产生之后后面的服务器即使myid比leader的大，但是leader已经产生了，所以自己只能是follower

7.  zkServer.sh status查看状态
	zkServer.sh start 启动Zookeeper集群
	zkCli.sh	启动客户端

8. Zookeeper客户端增删改查操作：
	> 1. 创建节点：默认创建的是持久节点，-e指定临时节点，临时节点不能有子节点
		create [-s] [-e] path data acl    # -s表示有序，-e表示临时节点，默认创建的是持久节点，创建是必须指定data
		create /0722 "I love wenwen"		# 创建持久化节点
		create -s /0722/xiaoqiang "xiaoqiang"    	# 创建有序的持久化节点
		create -e /0722/linshi	"linshi"			# 创建临时几点，客户端断开连接后自动删除
		create -s -e /0722/linshiyouxu "linshi youxu"   # 创建临时有序节点
	> 2. 读取节点数据
		get path [watch]	# 读取指定path的节点数据，watch表示监听该路径的内容
	> 3. 更新节点数据
		set path data [version]   # 更新指定节点的数据
	> 4. 删除指定节点
		delete path	[version]		# 删除指定的节点，delete不能递归删除，只能删除空的节点
		rmr path					# 递归删除指定的节点
	> 5. ls path [watch]			# 列出path下面的子节点，watch表示监听指定的path下子节点变化，这里的监听只会监听一次
	
9. 监听器的原理：观察者模式
	>1. 在main()线程中创建zkClient, 这时会创建两个线程，一个负责网络连接通信(connect), 一个负责监听(listener)
	>2. 通过connect线程将注册的监听事件发送给Zookeeper
	>3. 将注册的监听事件和客户端信息保存到监听列表中
	>4. Zookeeper监听到有数据或者路径发生变化时，就会将这个消息通知给监听线程

10. Zookeeper写数据流程：
	>1. 客户端发送写数据的请求到指定的服务器端
	>2. 指定的服务器接收到请求之后找到集群中的Leader，将请求转发给Leader来处理
	>3. Leader处理到请求之后会广播给所有的follower
	>4. follow收到leader的写数据命令，开始将数据写到具体的节点上面，数据写完之后通知Leader，写操作已完成
	>5. Leader收到大多数server完成操作的响应之后会通知客户端请求的服务器，客户端请求的服务器写操作已完成，
	该服务器再将信息返回到客户端